[paths]
included_dirs = [
    "workflow",
    "workflow/daemon",
    "workflow/model_service",
    "self",
    "app",
]

[api]
enabled = false
host = "0.0.0.0"
# port will be set to random if not specified
use_random_port = true
debug = false

[api_daemon]
enabled = true
host = "0.0.0.0"
port = "5005"  
use_random_port = true
debug = false
auto_start = false
command_timeout = 300  # 5 minutes
max_concurrent_commands = 10
enable_command_caching = true
enable_command_history = true

[llm]
provider = "openai"
model = "gpt-4-turbo"
openai_api_key = "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"  # Set your OpenAI API key here or via environment variable
temperature = 0.7
system_prompt = "You are the MCLI Chat Assistant."
