[paths]
included_dirs = [
    "workflow",
    "workflow/daemon",
    "workflow/model_service",
]

[api]
enabled = false
host = "0.0.0.0"
# port will be set to random if not specified
use_random_port = true
debug = false

[api_daemon]
enabled = true
host = "0.0.0.0"
port = "5005"  
use_random_port = true
debug = false
auto_start = false
command_timeout = 300  # 5 minutes
max_concurrent_commands = 10
enable_command_caching = true
enable_command_history = true

[llm]
provider = "openai"
model = "gpt-4-turbo"
openai_api_key = "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"
temperature = 0.7
system_prompt = "You are the MCLI Chat Assistant."